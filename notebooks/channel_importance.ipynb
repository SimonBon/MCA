{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel Importance Analysis\n",
    "\n",
    "Two complementary views on whether early fusion models ignore input channels:\n",
    "\n",
    "1. **Weight norm analysis** — directly inspect the first-layer conv weights; requires only the `.pth` checkpoint\n",
    "2. **Channel ablation** — zero out one marker at a time and measure embedding shift; requires the model + h5 data\n",
    "3. **Embedding effective rank** — how many dimensions are actually used in the representation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path('..').resolve()))\n",
    "from src.models import WideModel\n",
    "from src.models_early_fusion import ResNetBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Configuration ─────────────────────────────────────────────────────────────\n",
    "BASE = Path('/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/src/MCA/z_RUNS')\n",
    "\n",
    "RUNS = {\n",
    "    'CIM (channel-sep.)' : BASE / 'CODEX_cHL_CIM_VICReg',\n",
    "    'ResNet (early fus.)': BASE / 'CODEX_cHL_ResNet_VICReg',\n",
    "}\n",
    "\n",
    "MARKERS_TXT = Path('/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/data/MCI_data/h5_files/CODEX_cHL/used_markers.txt')\n",
    "H5_FILE     = Path('/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/data/MCI_data/h5_files/CODEX_cHL/CODEX_cHL.h5')\n",
    "VAL_IDX_TXT = Path('/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/data/MCI_data/h5_files/CODEX_cHL/val.txt')\n",
    "\n",
    "# CIM backbone config (must match the run's backbone config)\n",
    "CIM_CFG    = dict(in_channels=41, stem_width=32, block_width=4, layer_config=[1, 1])\n",
    "RESNET_CFG = dict(in_channels=41, base_width=64)\n",
    "\n",
    "ABLATION_N_CELLS = 512   # how many val cells to use for ablation (keep small for speed)\n",
    "PATCH_SIZE       = 32\n",
    "DEVICE           = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper — load backbone from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_backbone(run_dir: Path, backbone: torch.nn.Module) -> torch.nn.Module:\n",
    "    \"\"\"Load backbone weights from an mmengine checkpoint in run_dir.\"\"\"\n",
    "    ptr = run_dir / 'last_checkpoint'\n",
    "    ckpt_path = Path(ptr.read_text().strip())\n",
    "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "    state = ckpt['state_dict']\n",
    "    bb_state = {k[len('backbone.'):]: v for k, v in state.items() if k.startswith('backbone.')}\n",
    "    backbone.load_state_dict(bb_state, strict=True)\n",
    "    backbone.eval()\n",
    "    return backbone\n",
    "\n",
    "marker_names = np.loadtxt(MARKERS_TXT, dtype=str, delimiter=',')\n",
    "print(f'{len(marker_names)} markers: {marker_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 · Weight norm analysis\n",
    "\n",
    "For each model the first conv layer determines which input channels are attended to.  \n",
    "- **ResNet stem**: `Conv2d(41 → base_width, 3×3, groups=1)` — weight shape `[base_width, 41, 3, 3]`  \n",
    "  → per-channel norm = `w.norm(dim=(0,2,3))`  \n",
    "- **CIM stem**: `Conv2d(41 → 41×stem_width, 3×3, groups=41)` — weight shape `[41×stem_width, 1, 3, 3]`  \n",
    "  → each group of `stem_width` output rows belongs to one input channel  \n",
    "  → per-channel norm = `w.view(41, stem_width, 1, 3, 3).norm(dim=(1,2,3,4))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "cim    = load_backbone(RUNS['CIM (channel-sep.)'],  WideModel(**CIM_CFG))\nresnet = load_backbone(RUNS['ResNet (early fus.)'], ResNetBaseline(**RESNET_CFG))\n\n# ── CIM: depthwise weight [41*stem_width, 1, 3, 3]\n# group i occupies rows [i*stem_width : (i+1)*stem_width]\n# → reshape to [C, stem_width*1*3*3] then norm over dim 1\nw_cim = cim.stem[0].weight   # [C*D, 1, 3, 3]\nC, D  = CIM_CFG['in_channels'], CIM_CFG['stem_width']\nnorms_cim = w_cim.reshape(C, -1).norm(dim=1).detach().numpy()\n\n# ── ResNet: standard conv [base_width, 41, 3, 3]\n# → transpose to [41, base_width, 3, 3] then flatten and norm\nw_res     = resnet.stem[0].weight   # [base_width, C, 3, 3]\nnorms_res = w_res.permute(1, 0, 2, 3).reshape(C, -1).norm(dim=1).detach().numpy()\n\n# Normalise both to [0, 1] for easy comparison\nnorms_cim_n = norms_cim / norms_cim.max()\nnorms_res_n = norms_res / norms_res.max()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(16, 7), sharex=True)\n",
    "x = np.arange(len(marker_names))\n",
    "\n",
    "for ax, norms, label, color in zip(\n",
    "    axes,\n",
    "    [norms_cim_n, norms_res_n],\n",
    "    ['CIM  (channel-sep.)', 'ResNet (early fus.)'],\n",
    "    ['steelblue', 'tomato'],\n",
    "):\n",
    "    # sort by CIM norms so both plots share the same x-order\n",
    "    order = np.argsort(norms_cim_n)[::-1] if 'CIM' in label else np.argsort(norms_cim_n)[::-1]\n",
    "    bars = ax.bar(x, norms[order], color=color, alpha=0.85, edgecolor='white', linewidth=0.4)\n",
    "    ax.axhline(norms[order].mean(), color='black', lw=1.2, ls='--', label=f'mean = {norms[order].mean():.3f}')\n",
    "    ax.set_ylabel('Normalised stem\\nweight norm', fontsize=10)\n",
    "    ax.set_title(label, fontsize=11, fontweight='bold')\n",
    "    ax.set_ylim(0, 1.08)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(marker_names[order], rotation=75, ha='right', fontsize=8)\n",
    "\n",
    "fig.suptitle('First-layer weight norm per input channel', fontsize=13, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../notebooks/channel_weight_norms.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "for name, norms in [('CIM', norms_cim_n), ('ResNet', norms_res_n)]:\n",
    "    low = (norms < 0.1).sum()\n",
    "    print(f'{name}: {low}/{len(norms)} channels with norm < 0.1 (effectively ignored)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 · Channel ablation\n",
    "\n",
    "Zero out one channel at a time across a batch of val cells.  \n",
    "Sensitivity = `1 - mean cosine_similarity(baseline_embedding, ablated_embedding)`  \n",
    "A channel the model ignores → sensitivity ≈ 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Load a small batch of raw patches from the h5 file ───────────────────────\n",
    "val_idx = np.loadtxt(VAL_IDX_TXT, dtype=int)\n",
    "rng     = np.random.default_rng(42)\n",
    "chosen  = rng.choice(val_idx, size=ABLATION_N_CELLS, replace=False)\n",
    "chosen.sort()\n",
    "\n",
    "half = PATCH_SIZE // 2\n",
    "\n",
    "with h5py.File(H5_FILE, 'r') as h5:\n",
    "    DIM1      = h5['coords']['DIM1'][chosen]\n",
    "    DIM2      = h5['coords']['DIM2'][chosen]\n",
    "    sample_id = h5['coords']['sample_id'][chosen].astype(str)\n",
    "\n",
    "    patches = []\n",
    "    for d1, d2, sid in zip(DIM1, DIM2, sample_id):\n",
    "        img  = h5['data'][sid]['image']\n",
    "        s1, e1 = max(0, d1-half), min(img.shape[0], d1+half)\n",
    "        s2, e2 = max(0, d2-half), min(img.shape[1], d2+half)\n",
    "        p = img[s1:e1, s2:e2, :]   # [H, W, C]\n",
    "        # pad if needed\n",
    "        p = np.pad(p,\n",
    "                   ((d1-half - min(0, d1-half), max(0, d1+half - img.shape[0])),\n",
    "                    (d2-half - min(0, d2-half), max(0, d2+half - img.shape[1])),\n",
    "                    (0, 0)), mode='constant')\n",
    "        patches.append(p)\n",
    "\n",
    "# [N, H, W, C] → [N, C, H, W]\n",
    "X = torch.from_numpy(np.stack(patches)).permute(0, 3, 1, 2).float()\n",
    "print(f'Loaded {X.shape[0]} patches, shape {tuple(X.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def channel_sensitivity(backbone, X, device):\n",
    "    \"\"\"Returns (C,) array of sensitivity scores.\"\"\"\n",
    "    backbone = backbone.to(device)\n",
    "    X        = X.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        baseline = backbone(X)[0].squeeze(-1).squeeze(-1)  # [N, D]\n",
    "        baseline = F.normalize(baseline, dim=-1)\n",
    "\n",
    "        sensitivities = []\n",
    "        for c in range(X.shape[1]):\n",
    "            X_abl = X.clone()\n",
    "            X_abl[:, c] = 0.0\n",
    "            ablated = backbone(X_abl)[0].squeeze(-1).squeeze(-1)\n",
    "            ablated = F.normalize(ablated, dim=-1)\n",
    "            sim = (baseline * ablated).sum(dim=-1).mean().item()\n",
    "            sensitivities.append(1.0 - sim)\n",
    "\n",
    "    backbone.cpu()\n",
    "    return np.array(sensitivities)\n",
    "\n",
    "sens_cim    = channel_sensitivity(cim,    X, DEVICE)\n",
    "sens_resnet = channel_sensitivity(resnet, X, DEVICE)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(16, 7), sharex=True)\n",
    "order = np.argsort(sens_cim)[::-1]  # sort by CIM sensitivity\n",
    "\n",
    "for ax, sens, label, color in zip(\n",
    "    axes,\n",
    "    [sens_cim, sens_resnet],\n",
    "    ['CIM  (channel-sep.)', 'ResNet (early fus.)'],\n",
    "    ['steelblue', 'tomato'],\n",
    "):\n",
    "    ax.bar(x, sens[order], color=color, alpha=0.85, edgecolor='white', linewidth=0.4)\n",
    "    ax.axhline(sens[order].mean(), color='black', lw=1.2, ls='--',\n",
    "               label=f'mean = {sens[order].mean():.4f}')\n",
    "    ax.set_ylabel('Ablation sensitivity\\n(1 − cos sim)', fontsize=10)\n",
    "    ax.set_title(label, fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(marker_names[order], rotation=75, ha='right', fontsize=8)\n",
    "\n",
    "fig.suptitle('Channel ablation: embedding sensitivity to zeroing each marker', fontsize=13, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../notebooks/channel_ablation.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print the most and least sensitive channels for each model\n",
    "for name, sens in [('CIM', sens_cim), ('ResNet', sens_resnet)]:\n",
    "    top5    = np.argsort(sens)[::-1][:5]\n",
    "    bottom5 = np.argsort(sens)[:5]\n",
    "    print(f'\\n{name} — top-5 most sensitive:    {[(marker_names[i], round(sens[i],4)) for i in top5]}')\n",
    "    print(f'{name} — top-5 least sensitive:   {[(marker_names[i], round(sens[i],4)) for i in bottom5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 · Effective rank of embedding space\n",
    "\n",
    "Are the ResNet embeddings collapsing into a low-dimensional subspace?  \n",
    "Uses the saved `val_results.npz` files — no model or data loading needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_rank(Z):\n",
    "    \"\"\"Roy & Vetterli 2007: exp(entropy of normalised singular value distribution).\"\"\"\n",
    "    Z = Z - Z.mean(axis=0)\n",
    "    _, S, _ = np.linalg.svd(Z, full_matrices=False)\n",
    "    p = S**2 / (S**2).sum()\n",
    "    erank = np.exp(-np.sum(p * np.log(p + 1e-12)))\n",
    "    return erank, S, p\n",
    "\n",
    "results = {}\n",
    "for label, run_dir in RUNS.items():\n",
    "    npz = np.load(run_dir / 'val_results.npz')\n",
    "    Z   = npz['features']\n",
    "    er, S, p = effective_rank(Z)\n",
    "    results[label] = dict(S=S, p=p, erank=er, dim=Z.shape[1])\n",
    "    print(f'{label}: effective rank = {er:.1f} / {Z.shape[1]}  ({100*er/Z.shape[1]:.1f}% of dims used)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "colors = {'CIM (channel-sep.)': 'steelblue', 'ResNet (early fus.)': 'tomato'}\n",
    "\n",
    "# Left: singular value spectra\n",
    "ax = axes[0]\n",
    "for label, res in results.items():\n",
    "    S_norm = res['S'] / res['S'][0]\n",
    "    ax.plot(S_norm, label=f\"{label}  (erank={res['erank']:.0f}/{res['dim']})\",\n",
    "            color=colors[label], lw=1.5)\n",
    "ax.set_xlabel('Singular value index')\n",
    "ax.set_ylabel('Normalised singular value')\n",
    "ax.set_title('Singular value spectrum')\n",
    "ax.legend(fontsize=9)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Right: cumulative variance explained\n",
    "ax = axes[1]\n",
    "for label, res in results.items():\n",
    "    cum_var = np.cumsum(res['S']**2) / (res['S']**2).sum()\n",
    "    k90 = int((cum_var < 0.90).sum())\n",
    "    ax.plot(cum_var, color=colors[label], lw=1.5,\n",
    "            label=f'{label}  (90% var @ dim {k90})')\n",
    "ax.axhline(0.90, color='grey', ls=':', lw=1)\n",
    "ax.set_xlabel('Number of dimensions')\n",
    "ax.set_ylabel('Cumulative variance explained')\n",
    "ax.set_title('Cumulative variance')\n",
    "ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../notebooks/effective_rank.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIDL26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}