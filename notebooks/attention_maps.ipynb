{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# MCIANet Attention Map Visualisation\n",
    "\n",
    "Visualises the internal attention representations stored by `MCIANet` during a forward pass:\n",
    "\n",
    "| Attribute | Shape | Description |\n",
    "|---|---|---|\n",
    "| `backbone.last_spatial_masks` | `[B, C, 1, 12, 12]` | Per-channel spatial focus maps |\n",
    "| `backbone.attn1.last_attn` | `[C, C]` | Cross-channel attention after stage 1 (6×6) |\n",
    "| `backbone.attn2.last_attn` | `[C, C]` | Cross-channel attention after stage 2 (3×3) |\n",
    "\n",
    "**Requires**: a trained `CODEX_cHL_ATT_MASK_VP` checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1  Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# ── Paths — edit these to match your environment ──────────────────────────────\n",
    "CFG_PATH  = '/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/src/MCA/configs/_experiments_/CODEX_cHL_ATT_MASK_VP.py'\n",
    "CKPT_PATH = '/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/src/MCA/z_RUNS/CODEX_cHL_ATT_MASK_VP/iter_XXXX.pth'  # ← update\n",
    "H5_PATH   = '/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/data/MCI_data/h5_files/CODEX_cHL/CODEX_cHL.h5'\n",
    "MARKERS_PATH = '/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/data/MCI_data/h5_files/CODEX_cHL/used_markers.txt'\n",
    "VAL_IDX_PATH = '/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/data/MCI_data/h5_files/CODEX_cHL/val.txt'\n",
    "\n",
    "N_PATCHES = 6   # number of sample patches to load\n",
    "DEVICE    = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load marker names from HDF5\n",
    "with h5py.File(H5_PATH, 'r') as f:\n",
    "    all_markers = f['marker_names'][:].astype(str)\n",
    "\n",
    "# Filter to used markers if a list is provided\n",
    "used_markers_path = Path(MARKERS_PATH)\n",
    "if used_markers_path.exists():\n",
    "    used_marker_names = np.loadtxt(MARKERS_PATH, dtype=str, delimiter='\\n')\n",
    "    # Keep only markers that appear in the HDF5\n",
    "    marker_names = [m for m in used_marker_names if m in all_markers]\n",
    "else:\n",
    "    marker_names = list(all_markers)\n",
    "\n",
    "print(f'Markers ({len(marker_names)}):', marker_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2  Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "from mmengine.registry import MODELS, init_default_scope\n",
    "from mmengine.runner import load_checkpoint\n",
    "\n",
    "# Trigger custom_imports so MCIANet, MVSimCLR, etc. are registered\n",
    "cfg = Config.fromfile(CFG_PATH)\n",
    "init_default_scope(cfg.get('default_scope', 'mmselfsup'))\n",
    "\n",
    "model = MODELS.build(cfg.model)\n",
    "load_checkpoint(model, CKPT_PATH, map_location='cpu')\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "backbone = model.backbone\n",
    "print('Model loaded. Backbone type:', type(backbone).__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3  Load sample patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.registry import DATASETS\n",
    "from copy import deepcopy\n",
    "\n",
    "# Build a minimal val dataset using the config's val pipeline\n",
    "dataset_kwargs = deepcopy(cfg.get('_base_', {}))\n",
    "\n",
    "# Simpler: build MCIDataset directly with the val pipeline from config\n",
    "val_pipeline = [\n",
    "    dict(type='C_CentralCutter', size=cfg.get('cutter_size', 24)),\n",
    "    dict(type='C_ToTensor'),\n",
    "    dict(type='C_MultiView', n_views=[1], transforms=[None]),\n",
    "    dict(type='C_PackInputs'),\n",
    "]\n",
    "\n",
    "ds = DATASETS.build(dict(\n",
    "    type='MCIDataset',\n",
    "    h5_filepath=H5_PATH,\n",
    "    patch_size=cfg.get('patch_size', 32),\n",
    "    used_markers=MARKERS_PATH,\n",
    "    used_indicies=VAL_IDX_PATH,\n",
    "    pipeline=val_pipeline,\n",
    "    ignore_annotation=['Seg Artifact'],\n",
    "))\n",
    "\n",
    "print(f'Val dataset: {len(ds)} cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick N_PATCHES random indices and stack into a batch tensor\n",
    "rng = np.random.default_rng(42)\n",
    "sample_indices = rng.integers(0, len(ds), size=N_PATCHES).tolist()\n",
    "\n",
    "patches = []\n",
    "annotations = []\n",
    "for idx in sample_indices:\n",
    "    item = ds[idx]\n",
    "    # item['inputs'] is a list of tensors (one per view); take view 0\n",
    "    patches.append(item['inputs'][0])\n",
    "    annotations.append(item['data_samples'].get('annotation', ['?'])[0])\n",
    "\n",
    "x = torch.stack(patches).to(DEVICE)   # [B, C, H, W]\n",
    "print(f'Patch batch: {x.shape}  |  labels: {annotations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 4  Forward pass (populates stored attention attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _ = backbone(x)\n",
    "\n",
    "# Retrieve stored tensors and move to CPU for plotting\n",
    "spatial_masks = backbone.last_spatial_masks.cpu()   # [B, C, 1, 12, 12]\n",
    "attn1         = backbone.attn1.last_attn.cpu()      # [C, C]  (averaged over batch by MHA)\n",
    "attn2         = backbone.attn2.last_attn.cpu()      # [C, C]\n",
    "\n",
    "B, C, _, H_m, W_m = spatial_masks.shape\n",
    "print(f'spatial_masks : {spatial_masks.shape}')\n",
    "print(f'attn1         : {attn1.shape}')\n",
    "print(f'attn2         : {attn2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 5  Spatial focus maps\n",
    "\n",
    "For each biological channel, show the raw patch intensity alongside the 12×12 attention mask (upsampled to 24×24 for overlay)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "PATCH_IDX = 0   # which sample to visualise; change as needed\n",
    "\n",
    "patch_np    = x[PATCH_IDX].cpu().numpy()           # [C, H, W]\n",
    "masks_np    = spatial_masks[PATCH_IDX, :, 0]       # [C, 12, 12]\n",
    "# Upsample masks to input resolution\n",
    "masks_up    = F.interpolate(\n",
    "    spatial_masks[PATCH_IDX, :, 0].unsqueeze(1),   # [C, 1, 12, 12]\n",
    "    size=(patch_np.shape[-2], patch_np.shape[-1]),\n",
    "    mode='bilinear',\n",
    "    align_corners=False,\n",
    ").squeeze(1).numpy()                                # [C, H, W]\n",
    "\n",
    "ncols = 6\n",
    "nrows = int(np.ceil(C / ncols))\n",
    "fig, axes = plt.subplots(nrows, ncols * 2, figsize=(ncols * 4, nrows * 2.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for c in range(C):\n",
    "    ax_img  = axes[c * 2]\n",
    "    ax_mask = axes[c * 2 + 1]\n",
    "\n",
    "    img = patch_np[c]\n",
    "    msk = masks_up[c]\n",
    "\n",
    "    ax_img.imshow(img, cmap='inferno', vmin=0, vmax=img.max() + 1e-6)\n",
    "    ax_img.set_title(marker_names[c] if c < len(marker_names) else f'Ch{c}', fontsize=7)\n",
    "    ax_img.axis('off')\n",
    "\n",
    "    ax_mask.imshow(img, cmap='gray',   vmin=0, vmax=img.max() + 1e-6)\n",
    "    ax_mask.imshow(msk, cmap='hot',    alpha=0.6, vmin=0, vmax=1)\n",
    "    ax_mask.set_title('focus', fontsize=7)\n",
    "    ax_mask.axis('off')\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(C * 2, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "fig.suptitle(\n",
    "    f'Spatial focus maps  |  patch {PATCH_IDX}: {annotations[PATCH_IDX]}',\n",
    "    fontsize=11, y=1.01\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 6  Channel cross-attention heatmaps\n",
    "\n",
    "`attn1` (6×6 spatial scale) and `attn2` (3×3 spatial scale): row = query channel, column = key channel.  \n",
    "High values → the query channel attends strongly to the key channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_heatmap(attn: torch.Tensor, marker_names: list, title: str, ax):\n",
    "    \"\"\"Plot a C×C attention matrix as an annotated heatmap.\"\"\"\n",
    "    C = attn.shape[0]\n",
    "    labels = marker_names[:C] if len(marker_names) >= C else [f'Ch{i}' for i in range(C)]\n",
    "    sns.heatmap(\n",
    "        attn.numpy(),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        ax=ax,\n",
    "        cmap='viridis',\n",
    "        square=True,\n",
    "        cbar_kws={'shrink': 0.5},\n",
    "        linewidths=0,\n",
    "    )\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    ax.tick_params(axis='x', labelrotation=90, labelsize=6)\n",
    "    ax.tick_params(axis='y', labelrotation=0,  labelsize=6)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(22, 10))\n",
    "plot_attn_heatmap(attn1, marker_names, 'Cross-channel attention  (stage 1 – 6×6)', axes[0])\n",
    "plot_attn_heatmap(attn2, marker_names, 'Cross-channel attention  (stage 2 – 3×3)', axes[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 7  Channel importance ranking\n",
    "\n",
    "Row-sum of each attention matrix = total attention weight received by each channel.  \n",
    "Channels with high row-sums are consistently attended to by other channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_importance(attn: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"Mean attention weight received per channel (column-sum).\"\"\"\n",
    "    return attn.mean(dim=0).numpy()   # average over query rows → [C]\n",
    "\n",
    "\n",
    "def plot_importance(importance: np.ndarray, marker_names: list, title: str, ax, color: str):\n",
    "    C = len(importance)\n",
    "    labels = marker_names[:C] if len(marker_names) >= C else [f'Ch{i}' for i in range(C)]\n",
    "    order  = np.argsort(importance)[::-1]\n",
    "    ax.bar(range(C), importance[order], color=color, alpha=0.8)\n",
    "    ax.set_xticks(range(C))\n",
    "    ax.set_xticklabels([labels[i] for i in order], rotation=90, fontsize=7)\n",
    "    ax.set_ylabel('Mean attention weight')\n",
    "    ax.set_title(title, fontsize=11)\n",
    "\n",
    "\n",
    "imp1 = channel_importance(attn1)\n",
    "imp2 = channel_importance(attn2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "plot_importance(imp1, marker_names, 'Channel importance — stage 1 (6×6)', axes[0], '#4C8EDA')\n",
    "plot_importance(imp2, marker_names, 'Channel importance — stage 2 (3×3)', axes[1], '#E8735A')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 8  Multi-sample spatial mask overlay\n",
    "\n",
    "For a single selected biomarker channel, compare the spatial focus mask across all loaded patches to check for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_NAME = 'CD20'   # change to any marker in marker_names\n",
    "if CHANNEL_NAME in marker_names:\n",
    "    CHANNEL_IDX = marker_names.index(CHANNEL_NAME)\n",
    "else:\n",
    "    CHANNEL_IDX = 0\n",
    "    CHANNEL_NAME = marker_names[CHANNEL_IDX] if marker_names else f'Ch{CHANNEL_IDX}'\n",
    "    print(f'Channel not found; falling back to {CHANNEL_NAME}')\n",
    "\n",
    "patch_np_all = x.cpu().numpy()                      # [B, C, H, W]\n",
    "masks_up_all = F.interpolate(\n",
    "    spatial_masks[:, CHANNEL_IDX, 0].unsqueeze(1),  # [B, 1, 12, 12]\n",
    "    size=(patch_np_all.shape[-2], patch_np_all.shape[-1]),\n",
    "    mode='bilinear',\n",
    "    align_corners=False,\n",
    ").squeeze(1).numpy()                                # [B, H, W]\n",
    "\n",
    "fig, axes = plt.subplots(2, B, figsize=(B * 3, 6))\n",
    "if B == 1:\n",
    "    axes = axes.reshape(2, 1)\n",
    "\n",
    "for b in range(B):\n",
    "    img = patch_np_all[b, CHANNEL_IDX]\n",
    "    msk = masks_up_all[b]\n",
    "\n",
    "    axes[0, b].imshow(img, cmap='inferno', vmin=0, vmax=img.max() + 1e-6)\n",
    "    axes[0, b].set_title(f'{annotations[b]}', fontsize=8)\n",
    "    axes[0, b].axis('off')\n",
    "\n",
    "    axes[1, b].imshow(img, cmap='gray',  vmin=0, vmax=img.max() + 1e-6)\n",
    "    axes[1, b].imshow(msk, cmap='hot',   alpha=0.6, vmin=0, vmax=1)\n",
    "    axes[1, b].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('Raw', fontsize=9)\n",
    "axes[1, 0].set_ylabel('Focus overlay', fontsize=9)\n",
    "\n",
    "fig.suptitle(f'Spatial focus masks for \"{CHANNEL_NAME}\" across {B} patches', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
